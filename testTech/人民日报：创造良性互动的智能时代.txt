原标题 创造良性互动的智能时代作者 喻思南人工智能算法潜在的安全隐患、认知偏见、法律伦理冲突等往往是现实社会缺陷的反映。只有在机器与使用机器的人上两头着力，我们才能创造一个人工智能与人类良性互动的未来。语音点菜、刷脸买单、无人车送回家……60多年前，当一批年轻的科学家首次提出人工智能的概念时，或许没想到它带来的巨大变化；而今，得益于计算能力的提升、大数据的驱动以及深度学习的突破，人工智能正加快“进化”，日益改变着我们的生产、生活。技术是把双刃剑。应当看到，人工智能在高歌猛进的同时，对安全、法律伦理等也提出了新挑战。比如，一些专家担忧人工智能可能模糊虚拟世界和物理世界的界限，甚至重塑人类的生存环境和认知形态，并由此衍生出一系列棘手的道德伦理难题。知名物理学家霍金生前就认为，人工智能的短期影响由控制它的人决定，而长期影响则取决于人工智能是否完全为人所控制。从技术发展进程和逻辑看，这些担忧或许来得早了点。好在我们没有仅仅停留在争论上，针对人工智能潜在的风险，科学家和工程师们防患于未然，从产品设计标准、规范约束等方面提出了一系列试图控制智能机器系统的可行性方案。面对智能算法不可理解、缺乏透明造成的机器偏见，人们正加强评估人工智能使用的数据、算法以及模型，剔除可导致偏见的潜在因素；对于未来强人工智能环境下，具有准人格的机器如何与人协调相处问题，科学家也试图探索通过算法给智能机器嵌入人类的价值观和规范，让它们具有和人类一样的同情心、责任心、羞耻感等等。我们希望，在对人工智能程序进行监管的同时，让人工智能的算法遵循“善法”，吸取人类道德规范“善”的一面，从而控制机器的风险。当然，构建好机器法律伦理体系并不容易。现实中丰富的语言表达，微妙的情感诉求能被机器理解、接受吗？用量化的指标衡量善、恶等伦理概念可行吗？还有，谁来决定算法、设定标准？这些都是我们试图规范人工智能发展需要面临的难题。但给机器嵌入伦理的困难，并不意味着我们只能无所作为。机器学习输出的判断和行为，往往取决于它接受的信息。从这点看，人工智能本身并无对错，理想的状态下，当前基于深度学习的人工智能算法应当是中性、客观、高效的，其潜在的安全隐患、认知偏见、法律伦理冲突等往往是现实社会缺陷的反映，只不过在技术的视野中被放大了。因此，要让智能机器变得更完美，除了通过技术手段对算法进行审查或引导外，更重要的或许是正视、理解并改善现实社会环境。只有在机器与使用机器的人上两头着力，我们才能创造一个人工智能与人类良性互动的未来。