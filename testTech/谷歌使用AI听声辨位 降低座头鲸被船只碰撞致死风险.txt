新浪科技讯 10月31日下午消息，据iThome.com.tw报道，作为与AI for Social Good计划中的一部分，Google与美国国家海洋和大气管理局（NOAA）的太平洋群岛渔业科学中心合作，开发了一系列演算法来辨识水下座头鲸的声音，以进一步得知这些鲸鱼现身的时间和位置，协助减轻他们所面临的威胁。数十年来，许多组织尽力保护鲸鱼不受补杀，但仍有15种鲸鱼被列为濒临绝种的物种，而且即便是座头鲸这类已经恢复族群数量的物种，仍然不断会受到渔具缠绕和船只碰撞等威胁，因遭遇非自然因素死亡降低族群数量。为了更好地保护鲸鱼，第一步是要了解他们出现的位置和时间，以便规划正确的海洋保护区，对经过的船只发出警告，或是进行其他的保护措施。由于鲸豚类出现在水面上的时间并不多，要以视觉侦测他们十分困难，因此NOAA负责监测美国太平洋海域鲸鱼和其他海洋哺乳动物的太平洋群岛渔业科学中心，才会选择用水下录音机进行收音监听。鲸鱼的叫声可以在水下数百公里传递，以便和远方的伙伴沟通，而水下录音机能收集到这些鲸鱼的叫声。NOAA使用高频音讯记录软体套件（ High-frequency Acoustic Recording Packages，HARP），在太平洋12个地点（下图）录制水下的声音，有一些点在2005年就已经开始，目前累积了超过17万小时的水下录音，全部靠人来收听需要每天24小时工作连续19年。为了解决这个问题，Google和太平洋群岛渔业科学中心合作，开发了一系列演算法来辨识累积十多年水下鲸鱼的叫声，Google要以深度神经网路自动辨识这些录音中记录到的鲸鱼种类，而目前从座头鲸开始，要从这些录音中辨识出座头鲸并不间单，海洋很大，座头鲸也不是唯一会发出声音的动物，水下录音机会录制到各种声音，而且即便同是座头鲸的声音，也会因为雨声或是船只的噪音，混淆机器学习模型的判断。此外，鲸鱼和水下录音机的距离，也会影响声音讯号的强度。Google提到，之所以要从座头鲸开始，是因为座头鲸的叫声特别难分辨，不像蓝鲸或是长须鲸会发出固定典型的声音，座头鲸会因时间不同，制造出复杂且多变的声音。在过去几年，Google的AI Perception团队已经开发了一系列音讯事件分析技术，这些技术被大量应用在YouTube非语音字幕、影片分类以及索引上。另外，Google也发布了AudioSet评估资料集，并开源了一些机器学习模型原始码，推动社群研究，而现在这些研究成果被用在鲸鱼保护研究上。Google以NOAA现有标记过的水下声音资料集来训练座头鲸分类器。Google将这些水下声音转以视觉频谱表示，越多的标记频谱资料训练，就能让模型更精准的标记出录音中的座头鲸声音。现在系统已经可以根据录音中的座头鲸声音，在地图上标记出他们出现的时间地点。