原标题 发展人工智能，治理需跟上作者 李辉作为新一轮产业变革的重要驱动力，人工智能正在对经济社会发展和人类生活产生深刻影响，也带来方方面面的挑战。10月31日，习近平总书记在中共中央政治局第九次集体学习时强调，要整合多学科力量，加强人工智能相关法律、伦理、社会问题研究，建立健全保障人工智能健康发展的法律法规、制度体系、伦理道德。人工智能不仅是一个技术问题，也是一道治理考题。以无人驾驶技术为例，在全球范围内已出现多起事故，甚至造成人员伤亡，然而，并没有法律对此作出明确规定。当人们向算法让渡了部分决策权，也会让归责成为难题。在这个意义上，技术进步是一柄“双刃剑”，一方面可以造福人类，另一方面在缺乏规范和制约的情况下，也有可能损害社会公共利益。处理好人工智能在法律、安全等方面提出的新课题，需要完善治理，让技术创新运行在制度的轨道上。事实上，如何对人工智能进行规范，在世界范围内还未形成共识。在不少国家，无人驾驶领域的立法一直在讨论中，看法不一；在中国，无人驾驶的汽车能否上路、是否符合道路交通安全法，也引发了一系列讨论。欧盟最新发布的《通用数据保护条例》中，也没能对人工智能涉及的隐私风险、数据保护风险做出符合大众期待的回应。每当一种新技术出现，都会有关于旧的治理规则是否适用、是否需要升级，以及是否需要制定新的治理规则的讨论。面对日新月异的人工智能技术及其引发的问题，如何用法律条文探寻最佳应对方案、凝聚对未来的共识，是一项艰巨挑战。完善与人工智能相关的法律法规，关键在于明确归责原则：一旦问题出现，哪些是人的责任，哪些是算法的责任？归责原则实际上就是对算法做出评价，而算法本身并不透明，如何对其进行评估？对此有三种解决方案：不用算法，使算法透明，审查算法输出。完全避免算法不现实，除了算法，几乎没有其他工具可以处理大量的数据。而算法透明化则难以操作，这相当于要求普通人也能理解算法。因此，审查算法输出是目前的最佳方案。这一方案的要义在于，不管算法的内在工作机制，只根据其结果的公正性对其进行评价。在此方案下，监管成本更低，可操作性更强，归责原则的确定也更明确，具有立法实践的意义。面对科技的迅速发展，我们始终在探索人工智能的法律解决方案和治理模式，致力于形成一套务实管用、行之有效的方法。比如，相关部门对人工智能领域的新应用、新尝试给予足够的创新空间，但必要的监管同样不可或缺；一旦发现安全问题、突出风险，监管力量会及时介入，甚至采取多部门联合调查处理的方式封堵隐患、解决问题。这样的模式，既呵护了创新，也有利于防范系统性风险，为人工智能健康发展提供了保障。人工智能的治理问题是当前一项重大挑战，世界各国和国际组织都参与其中，这也让人工智能的治理成为全球治理的一部分。如果此时缺位，可能会在新一轮规则制定中陷入被动。如今，中国在人工智能领域的技术探索已处于世界前列，有些部分甚至进入了“无人区”。创新先行，治理必须跟上，如此才能充分享受创新带来的红利，撬动发展的未来。